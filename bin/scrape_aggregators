#!/usr/bin/env python
"""Simple commandline interface for scraping aggregator sites for live stream URLs."""
import argparse
import logging
from streamscrape import other

if __name__ == "__main__":
    parser = argparse.ArgumentParser(
        description="""
        Script to scrape several major aggregators for live stream URLS.
        """
    )
    parser.add_argument(
        "-v",
        "--verbose",
        dest="verbose",
        action="store_true",
        help="Output INFO level logging.",
    )
    parser.add_argument(
        "-vv",
        "--veryverbose",
        dest="debug",
        action="store_true",
        help="Output DEBUG level logging.",
    )
    args = parser.parse_args()

    if args.debug:
        log_level = logging.DEBUG
    elif args.verbose:
        log_level = logging.INFO
    else:
        log_level = logging.ERROR

    # Configure logging for this application
    log = logging.getLogger("streamscrape")
    log.propagate = 0  # prevent propagation to the root logger
    ch = logging.StreamHandler()
    log.setLevel(log_level)
    ch.setLevel(log_level)
    formatter = logging.Formatter("[%(levelname)s] %(name)s - %(message)s")
    ch.setFormatter(formatter)
    log.addHandler(ch)

    # Call the main routine
    result = other.scrape()
    for r in result:
        print("[{}] {} ({})".format(r["timestamp"], r["url"], r["ip"]))
